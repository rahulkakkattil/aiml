{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT7MKZuMRaCg"
   },
   "source": [
    "# Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaxAQxNUIakB"
   },
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "goHCpf5YIaCT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, TimeDistributed, Flatten, Dense,MaxPooling1D,Dropout,Conv1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq4RCyyPSYRp"
   },
   "source": [
    "### Loading the dataset (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGCtiXUhSWss",
    "outputId": "4a2dc76c-a91b-41c0-dbad-f46e765cbd48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "vocab_size = 10000 #vocab size\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fCPC_WN-eCyw"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "vocab_size = 10000 #vocab size\n",
    "maxlen = 300  #number of word used from each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMEsHYrWxdtk"
   },
   "source": [
    "## Train test split ( 5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "h0g381XzeCyz"
   },
   "outputs": [],
   "source": [
    "#load dataset as a list of ints\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "#make all sequences of the same length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test =  pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4aZvqIBWaLG-"
   },
   "outputs": [],
   "source": [
    "x=np.concatenate((x_train,x_test),axis=0)\n",
    "y=np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tZhMAgaNeCy5"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jy6n-uM2eCy2",
    "outputId": "193bc37e-6693-4aae-b281-5943f549c21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (40000, 300)\n",
      "Shape of y_train : (40000,)\n",
      "Shape of X_test : (10000, 300)\n",
      "Shape of y_test : (10000, 300)\n"
     ]
    }
   ],
   "source": [
    "#printing the shape\n",
    "print('Shape of X_train :',x_train.shape)\n",
    "print('Shape of y_train :',y_train.shape)\n",
    "print('Shape of X_test :',x_test.shape)\n",
    "print('Shape of y_test :',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOuequ41f7Cm",
    "outputId": "8b0f5c8a-fc39-4f00-9e1e-7b7bb46b53e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value of a word index: 9999\n",
      "Maximum length num words of review in train: 300\n"
     ]
    }
   ],
   "source": [
    "train_len = [len(sequence) for sequence in x_train]\n",
    "test_len = [len(sequence) for sequence in x_test]\n",
    "print('Maximum value of a word index:', max([max(sequence) for sequence in x_train]))\n",
    "print('Maximum length num words of review in train:', max([len(sequence) for sequence in x_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCdiSqJff_-9",
    "outputId": "3aac2a9a-b6c4-4083-ab6b-0803a113ea88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "especially the ? and the ? another problem of course is the huge gaps in the plot bakshi was in a rush to finish this movie and he somehow hoped to ? a book and a half in little more than two hours the new trilogy by peter jackson does it in about twice that time far too many important bits were left out and i don't refer only to tom ? which i think was lovely in the book but would look silly in a movie and of course the ending which is completely sudden and out of place i'm not even sure if bakshi originally intended to end the film there or if he even had any idea where he's going to end it br br the characters well most of them were okay the ? don't look so bad except for the gay sam did you know that the producers of the new trilogy originally wanted to make sam a woman so there would be a feminine lead character if you're a ? fanatic like me watch this movie though i'm not too sure about buying it what special features does the dvd version have anyway but know in advance that you're not going to watch a real ? of the rings ? but not much more than a historical curiosity which probably looks not much better than the 60s version would have had the beatles carried on with their plan i actually think a psychedelic lotr could have been quite cool the idea was to cast george as ? paul as ? ? as sam and john as ? if you didn't read the book or didn't like it much or don't like animation films or don't want to see a half finished movie stay away\n",
      "The sentiment for the above review is: Negative\n",
      "\n",
      "\n",
      "adventure alive especially when one of the soldiers is against all types of violence and another one continuously stares at video images of her cute 3 year old son the hills have eyes ii completely lacks  as to be expected  originality logic and plausible situations the mutated ? aren't nearly as menacing as their colleagues in part one mainly because they aren't organized this time and only just behave like ? and sex hungry prototype monsters since you don't care for the amateur g i joe heroes and definitely don't feel any sympathy for the eyes in the hills this film is a whole lot less compelling and involving than last year's original most ? this second film isn't nearly as violent and gory as the first sequels usually compensate the lack of suspense and the absence of surprise twists with extra bloodshed and more graphic killing sequences but the action in this sequel is really tame compared to the sick footage featuring in its predecessor there are a handful of scenes to satisfy the ? horror fanatics  mainly showing soldiers falling down ? or getting shot by their own guns  but there sadly aren't any outrageous pick axe battles or ? dog attacks what a shame what's the point of a sequel if it even fails to ? the level of ? and or gratuitous filth of the original luckily enough the film is never boring or unnecessarily sentimental and you'll have the most fun ? all the things that don't make the slightest bit of sense for example ? falling out of people's ? heads women without any muscle power cast as tough ass soldiers and  my personal favorite  ? the one soldier with a speaking ? to operate the radio ?\n",
      "The sentiment for the above review is: Negative\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(np.concatenate((y_train, y_test)), return_counts=True)\n",
    "sentiments = {1: 'Positive', 0: 'Negative'}\n",
    "\n",
    "def interprete_review(sequence):\n",
    "    id_to_word = dict([(value, key) for (key, value) in imdb.get_word_index().items()])\n",
    "    decoded_review = ' '.join([id_to_word.get(idx-3, '?') for idx in sequence])\n",
    "    print(decoded_review)\n",
    "    \n",
    "review_id1 = np.random.choice(train_len)\n",
    "interprete_review(x_train[review_id1])\n",
    "print('The sentiment for the above review is:', sentiments.get(y_train[review_id1]))\n",
    "print('\\n')\n",
    "review_id2 = np.random.choice(test_len)\n",
    "interprete_review(x_test[review_id2])\n",
    "print('The sentiment for the above review is:', sentiments.get(y_test[review_id2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dybtUgUReCy8"
   },
   "source": [
    "## Build Keras Embedding Layer Model (30 points)\n",
    "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
    "\n",
    "* The embedding layer can be used at the start of a larger deep learning model. \n",
    "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
    "* Use the embedding layer to train our own word2vec models.\n",
    "\n",
    "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5OLM4eBeCy9",
    "outputId": "b2348e4e-cfa7-4089-a45c-c0b60237be61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 300, 256)          2560000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 300, 256)          327936    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 300, 128)          163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 150, 64)           41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 75)                42000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 76        \n",
      "=================================================================\n",
      "Total params: 3,135,004\n",
      "Trainable params: 3,135,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256, input_length = maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(256, 5, padding = 'same', activation = 'relu', strides = 1))\n",
    "model.add(Conv1D(128, 5, padding = 'same', activation = 'relu', strides = 1))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(64, 5, padding = 'same', activation = 'relu', strides = 1))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(LSTM(75))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Adding callbacks\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 0)  \n",
    "mc = ModelCheckpoint('imdb_model.h5', monitor = 'val_loss', mode = 'min', save_best_only = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxNDNhrseCzA",
    "outputId": "023a312e-a338-4336-d2bd-d393868cf0cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 29s 83ms/step - loss: 0.5080 - accuracy: 0.7088 - val_loss: 0.2586 - val_accuracy: 0.8947\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25861, saving model to imdb_model.h5\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.1829 - accuracy: 0.9301 - val_loss: 0.2698 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25861\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batches = 128\n",
    "#using 20% of data as validation set\n",
    "history = model.fit(x_train, y_train, epochs = epochs, batch_size = batches, validation_split = 0.2,verbose = True, callbacks = [es, mc]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igq8Qm8GeCzG"
   },
   "source": [
    "## Accuracy of the model  & Retrive the output of each layer in keras for a given single test sample from the trained model you built (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3CSVVPPeCzD",
    "outputId": "604211bd-43c8-4ccf-a842-e60c150e2f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1729 - accuracy: 0.9360\n",
      "Training Loss: 0.1729 and Accuracy: 93.60%\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2658 - accuracy: 0.8906\n",
      "Test Loss: 0.2658 and Accuracy: 89.06%\n"
     ]
    }
   ],
   "source": [
    "tr_loss, tr_acc = model.evaluate(x_train, y_train)\n",
    "print('Training Loss: %.4f and Accuracy: %.2f%%' % (tr_loss, tr_acc * 100))\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('Test Loss: %.4f and Accuracy: %.2f%%' % (loss, acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg-taqVakbF8"
   },
   "source": [
    "**Observation**\n",
    "\n",
    "- Test acuracy = 89.06%\n",
    "-Train accuracy is 93.6%\n",
    "- Model is Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "0AqOnLa2eCzH",
    "outputId": "5fec227f-3775-49cf-9a04-fa4d27aa7f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing accuracy: 89.05999999999999\n",
      "\n",
      " Confusion matrix:\n",
      " [[4132  861]\n",
      " [ 233 4774]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix ')"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAFUCAYAAACgKW6XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU5dnG8d8FKiBGsGEBC7ZXjSYx9hgNUWOLBmM3MaLBkkRTNDGS5LWXWF5bjCWoRI0FW+xiVASxRMSosRuxgyBGKYICwt7vH89ZnF12lznjzu6U6+vnfJh5zplz7lnk3qed5ygiMDOz4nTp7ADMzKqJk6aZWQ5OmmZmOThpmpnl4KRpZpaDk6aZWQ5Omh1M0l6SHpI0TdIcSf+RdJ6kVcp0va0lPS1ptqR2m18m6SRJ/22v8xV5vZD0Wiv7X8v2n5TzvJvn+YykAdl1NsxzHasdTpodSNK5wE3AG8CPgB2B84HtgYvLdNm/ANOAnYCt2vG8V2Tn7Eizgf6SNi0slLQZsEa2P6/NgRNzHP806ef4egnXshqwWGcHUC8k7Q4cAwyOiGEFux6WNJSUQMthPWBoRDzcnieNiAnAhPY8ZxFmkZLW/sBTBeX7Aw8Bm5TrwpIEdIuIGcAT5bqOVT7XNDvO0cDTzRImABExPyJGNL6XtLykqyV9KOkTSaNbqF29Jen/JB0taYKkqZKGS+qd7R+QNce7AhdmTcqrsn0h6ahm52vS3JbUW9IVkt7LmvbvSLq8teOzsv6Sbpc0Q9LHku6StHazY0LSLyWdIekDSVMkXSypW5E/x+HAvlkSa0xm+2blTUjaStKdkiZJmiXpWUk/LNh/MHBRQVwhaXTh95P0TUnjSLXYfZo3zyXtI6lB0vYF510j+xmcXuR3siripNkBJC0OfAO4r8iP3E5q+v4G2I/09zSqeQIiJYvtgcOB44DdgDOyfY3NSIBzs9en5gj7POCbpGS/E/B7oNU+0SzpjQTWBw4DDgb6k2rSyzY7/NfAKsCBwDnAEcAvi4zr78CKWWwA2wArZOXNrQ48BgwGdgduBf4q6YBs/z2knw2kn89WwM8KPr8kcDWpK2Jn4MnmF4iIm4EbgWGSls6S+F+BN4GTi/xOVkXcPO8YywHdgHcWdaCknYGtgQGNTWpJDwFvAceSEkyjz4A9ImJedtwGpKbqzxqbkVmF7K2IyNuk3By4OCJuLCi7to3jDwFWA9aNiDeyeMaS+m+PAP5YcOxbEXFw9vofkrYG9gTOXlRQETFN0n2k7/lI9ud9ETE9+66Fxy6ofWbJbAzQj5TUb4iIDyS9lR3b0s+nB3BMRNxRcJ6VWzjuSOAFUv/0v0m/IDePiLmL+j5WfZw0O1Yxo9ebA1MK+yAjYpaku/m8dtVoVGPCzLwE9JG0eER89gVjfRY4VtJ84MGI+E8RcT/dmDCzuCdIeqyFuO9v9v4lYFOKNxy4QNIxwN7AL1o6SNIypNreQKAvqasCYGKR1wlgxCIPivhI0mHA3cBc4JSI+HeR17Aq4+Z5x/gQmEOqiS3KysCUFsrfB5o3c6c1ez8XEKlW+0UdReomOAF4NZvSs38bx6+cxdhcsXF3zxHbncBSwOlAT+CuVo67itS9cQ5poG0zYFiOa03NUVt8iPRduwCXL+JYq2JOmh0gq/U9RnFTdCYBfVooXxH4qJ1CmgMs0axsmcI3ETEtIn4RESsBXwXGAtdlXQAt6Yi4G2ObRarVHQ3clb1vQlJ3Uh/viRHx54h4KCKeIt//83nmtZ5JqslOBi7I8TmrMk6aHecCYFNJg5rvkNQl68uElJz6SNq2YP+SwHeBR9splgmkAZsF1ycNKLUoIp4j9ad2IU1haslYYBNJ/QvO25fUv9decRe6lFTDvKyV/d1I8c4piOdLwPeaHTc325enptuEpAHAz4GfkgadDpC0V6nns8rmPs0OEhF3SToPuDIb+LgDmElKQj8hDfTcFxH/kPQ4cKOkIaSm/W9IgxLntFM4twFHSnqGNFBzKLB04QGSHs2Oe4FU4zqMNE9yoRHkzFWkEfwRkk4A5pMmjf+XNMG+XUXEaGB0G/unZ1OFTpA0A2gAhgDTafpdX8n+/GU24DYjIl4tNg5JS5Ga/DdGxC1Z2V+ASyWNiYgPiv9WVg1c0+xAEfFrUh/bOsD1wAOk6TcjSbWURntk+y4Abib1U24XEePbKZSTs/OeRkp2z5KmyRT6J2na0C2ku5iWB3bJJrUvJCLmADuQktCVpKk675BmAbRr8zyHH5B+KVwDXEiacnRNs2MeIf0y+iWptpw3wZ9L+oV2ZEHZb0i/EFurBVsVkx93YWZWPNc0zcxycNI0M8vBSdPMLAcnTTOzHJw0zcxyqKp5mp/ec4GH+qvUtoe1tAiRVYtx743Roo9a2Gf/faOkf7OLL79mSdfrCK5pmpnlUFU1TTOrMg3zOzuCduekaWblEw2dHUG7c9I0s/JpcNI0MytauKZpZpaDa5pmZjm4pmlmloNHz83McnBN08wsB/dpmpkVz6PnZmZ5uKZpZpaDa5pmZjl49NzMLAfXNM3McnCfpplZDjVY0/QixGZmObimaWbl4+a5mVnxIjx6bmZWvBrs03TSNLPycfPczCwH1zTNzHLwHUFmZjm4pmlmloP7NM3McnBN08wsB9c0zcxycNI0Myue7wgyM8vDNU0zsxw8EGRmloNrmmZmOdRgTdOLEJuZ5eCappmVj5vnZmY51GDz3EnTzMrHNU0zsxycNM3McnDz3MwsB9c0zcxyqMGapudpmln5NDSUthVBUldJz0i6O3vfX9JYSeMl3Shpiay8W/Z+fLZ/jYJz/C4rf1XSTsVc10nTzMonGkrbivNL4OWC92cB50fE2sBUYHBWPhiYmpWfnx2HpA2A/YEvAzsDl0jquqiLOmmaWfmUqaYpqR/wXeCK7L2A7YBbskOuBvbIXg/M3pPt3z47fiAwPCLmRMSbwHhg80Vd20nTzMqnxKQp6XBJTxVshzc78wXAb4HGDLscMC0i5mXvJwB9s9d9gXcBsv3Ts+MXlLfwmVZ5IMjMyieixI/FUGBoS/sk7QZMiYh/SRpQenClcdI0s/Ipz5SjrYHvSdoV6A4sDVwI9Ja0WFab7AdMzI6fCKwKTJC0GNAL+LCgvFHhZ1rl5rmZlU8Z+jQj4ncR0S8i1iAN5DwUET8ERgF7Z4cNAu7IXt+ZvSfb/1BERFa+fza63h9YB3hyUV/JNU0zK5+Onad5HDBc0mnAM8CVWfmVwN8kjQc+IiVaIuJFSTcBLwHzgCOjiIcaOWmaWfmU+Y6giBgNjM5ev0ELo98RMRvYp5XPnw6cnueabp6bmeXgmqaZlU+Jo+eVzEnTzMrHC3aYmeXgpGlmlkMNrnLkpGlmZRMN7tM0Myuem+dmZjm4eW5mloOb52ZmObh5bmaWg5OmlWJ+QwM/OP9W+vTqyUWH7srwR57nujHP8e6HMxh1ysEss1QPAEa98CaXjHgSSSzWpQvH7rE1G6+5Mq9M/C9n3DKGmbPn0rWLOHSHTdhp47U7+VvVnwMO24c9frAbEcH4V97glKPPZO6cufz0uEPZfrdv09DQwK3X3M6NV97K6muvxgnnDWG9jdbl0rOu4NrLhnd2+J3DdwRZKa4f8zz9+/Rm1pzPAPha/5XY5surc+jFdzY5bot1+jHgy2sgif+89yG/veZ+bh9yAD0WX4xTf7Adq6/QmynTZ/GD825hq/VWZeke3Trj69SlFVZanv0G781+A37EnNlzOeOyk9hx4HZIYsVV+rDPtgcSESyzXG8AZkydwbnH/4lv7fzNTo68k9VgTbNDF+yQtJ6k4yT9KduOk7R+R8bQ0d6fNpNHXn6bPbf8/Guu128F+i679ELHLtltcdKjS+DTuZ+hrHz1Pr1ZfYX0j7FPr54su1QPps78tOyxW1OLLdaVbt270bVrV7r36M4H73/IXgftwRXnX01kNaqpH05b8OdL/36FefMWudJYbWuI0rYK1mFJU9JxwHBApIU+n8xe3yBpSEfF0dHOuf0xfrXbVguS4aI89Nwb7HHmDfz88ns5af9vL7T/+bff57P581l1uV7tHaq14YPJ/+XaS4dz17ibGfHsbcz6eBZjHx5H39VX4Tvf246rRwzlwmvPZtX+/To71MpS3qdRdoqOrGkOBjaLiDMj4tpsO5O0/t3gRXy2Ko158S2WWaoHG6y6QtGf2e4ra3L7kAM4/8c7c8mIpotIfzBjFv97/UhO3v/bdOlSXBK29vGlXkux7U7fZOAW+7HLxt+n+5Ld2WXP77BEt8WZO2cug3Y5nNuvu5vjzzuus0OtLK5pfiENwCotlK/M50+UW0jhU+muvO/xsgVXDs++OZmHX3yLXU69liF/e4Bxr03k99c+WNRnN1lrFSZ8OGNBM3zm7Ln8/PJ7OWrXLfjKGiuVM2xrwebbbMp7705i2kfTmT9vPqPuHcNXNt2QKZM+YNS9YwAYNWIM66y/VidHWlmioaGkrZJ15EDQr4CRkl7j88dmrgasDRzV2ocKn0r36T0XVPavoGZ+sduW/GK3LQEYN34i14z+N2ccuEOrx7/zwXRWXX5pJPHyhA+YO6+B3j2789m8+Rzz1/vYbdN1+c5X/Y+yM0ye+D4bfX0DuvXoxpxP57DZNzfh5edeYdbMT9hk6415b/gkvr7V13jnjXcXfTKrah2WNCPiPknrkprjjc8WngiMK+a5HLXk+jHPcdWoZ/nw40/Y9/9u4pvrr8aJ+32bkc+9wV1PvcpiXbvQffHFOPug7yCJ+599nadfn8S0WbO5c9yrAJxywHas13f5Tv4m9ePFZ15m5D2jufYfVzB/3nxefeE1brv2Lrp178apfz6eHxy2L5/M+oTTfnM2AMutsCxXjxhKzy/1JBoa2P/QvdlvwEHMmvlJJ3+TDlbhTe1SKIqYRyWpD9AzIt7M3gs4DNgAGBkRd5U1yky11TTtc9se9vfODsG+gHHvjSmpE33WaQeW9G+25/9eW7Gd9sX2aV4FHF3w/hTgEmBn4DZJB7dvWGZWE+p4IOjrwEMAkroAPwF+HxHrkZ7k9qvyhGdmVa0Mzz3vbMUmzV7Ah9nrTYBlgeuy9w+RBnPMzJqq45rmBFL/JcB3gVciYmL2vhcwu70DM7MaUIOT24sdPR8GnC1pB1LS/F3Bvi2Bl9s7MDOrARVeayxFUUkzIv4oaSKwGfBzUhJttCxwRRliM7MqV+kT1UtR9DzNiLgGuKaF8p+0a0RmVjtqsKZZ9G2UkrpJ+qmkKyXdL2mdrHy/Wl+pyMxKVIMDQUXVNLM7eR4gDfr8CxgAfCnbvQ2pn/OgMsRnZtWswgd1SlFsTfNPwDvAGsBOQOFs/YeBOl9p1cxaVK81TVJtcp+ImCapa7N975NWKjIzayIqPAGWotikORvo0cq+vsC09gnHzGpKDSbNYpvnDwC/l1S4XHhI6kaagnRvu0dmZtWvBm+jLLameSzwGDCelEADOAH4MrAEsGdZojOz6lavNc2IeBf4KnAZaTDodVI/5s3AJhExuVwBmlkVq+OBICJiKnB8tpmZ1aVi52kuBnSNiDkFZTuSFvEYExFPlyk+M6tixSxyXm2KrWneCEwHfgwg6RfABcAcoKukPSPi7vKEaGZVq8Kb2qUodvR8S5qOkB8LnBsRPUiLdfyhvQMzsxpQx32aywGTASRtRHoU72XZvpuBH7Z/aGZW7WpxcnuxNc33SaPmkJ4L9HZEvJ6970Ebzy03szpWxzXNm4GzJH0VOAT4c8G+jYHX2jswM6sBNVidKjZpDgFmkBYhvhQ4o2DfJqSBIjOzJmqxeV7syu3zSI/tbWmf7wYys5bVa9KU1AfoGRFvZu8FHEaapzkyIu4qX4hmVrVqsHle7EDQVcDRBe9PAS4hDQrdJung9g3LzGpBNERJWyUrNml+nfR8cyR1AX4C/D4i1gNOB35VnvDMrKo1lLhVsGKTZi/gw+z1JqQnUF6XvX8IWLud4zKzGlDPNc0JpP5LSM8DeiUiJmbve5EWKTYza6oGa5rFTjkaBpwtaQdS0vxdwb4tgZfbOzAzq341+Fy1otfT/CNphfbJ2Z9/Kti9LOn+czOzpspU05TUXdKTkv4t6UVJJ2fl/SWNlTRe0o2SlsjKu2Xvx2f71yg41++y8lcl7bSoa+dZT/Ma4JoWyn9S7DnMrL6UsaY5B9guImZKWhx4VNII4Bjg/IgYLukyYDDphpzBwNSIWFvS/sBZwH6SNgD2Jz2FYhXgQUnrRsT81i5cbJ8mkNbVlLSmpA2ab6V8azOzUkQyM3u7eLYFsB1wS1Z+NbBH9npg9p5s//bZfPOBwPCImJPNQx8PbN7WtYud3L44qUk+COjWymHNH+1rZvWujH2a2ePE/0WavXMx6TE807I7GCENYPfNXvcF3oV0h6Ok6aTV2/oCTxSctvAzLSq2pnkCsBupiivgKNLCHSOBt4DdizyPmdWRaChtk3S4pKcKtsMXOnfE/Ij4GtCPVDtcryO+U7FJc1/gJOCm7P2TEXFNROwIPEqq4pqZNVFq0oyIoRGxacE2tNVrREwDRgFbAb2zx/NASqaNUyMnAqvCgsf3NM49X1DewmdaVGzSXBX4T9Y5OhtYpmDfdcBeRZ7HzOpIqUlzUSStIKl39roH8B3S1MdRwN7ZYYOAO7LXd2bvyfY/FOkBRncC+2ej6/2BdYAn27p2saPnk4De2es3gW2BB7P3axV5DjOrN6FynXll4OqsX7MLcFNE3C3pJWC4pNOAZ4Ars+OvBP4maTzwEWnEnIh4UdJNwEvAPODItkbOofikORrYBrgLuBw4R9LapGH//YAbiv2mZlY/yjXlKCKeIy2A3rz8DVoY/Y6I2cA+rZzrdNIaGkUpNmn+AVg+u8AF2VD93qRHXVxEK2ttmll9i4ay1TQ7TbGLEE8me7Ba9v584PxyBWVmtaEWb6Ms+o4gM7O8onx9mp2m1aQpaRxphn1RIqLNWfRmVn/qrab5IjmSpplZc3XVpxkRB3dgHGZWg6IGq11t9mlK2oi0MsiEVvb3BZaNiOfLEZyZVbdarGm2ekeQpL1IM+N7t3YM6c6gsZJ8G6WZLSQaVNJWydq6jfJwYFhEvNDaAdm+K0kPWjMzayKitK2StZU0NwPuLeIc97GI9efMrD7VW01zSWBGEeeYkR1rZlbz2kqaE4D1izjHBixiKSUzq08RKmmrZG0lzbuBX0vq2doBkpYCjiYt5GFm1kS5lobrTG0lzTOApYDHJe0qacFjLiQtIWkX4JHsmD+WN0wzq0YNoZK2StbW5PYpkrYjLTJ8NzBP0geku4RWID3I6F+kJ8JN6Yhgzay6VHpTuxRtTm6PiFeBTSVtS1p4uPGBQxOB0RHxaJnjM7MqVukj4aUodmm4McCYMsdiZjWm0udclsJLw5lZ2dRtTdPMrBSVPqhTCidNMyubuhsIMjP7ItynaWaWQ101zyUdlOdEEXHNFw/HzGpJvTXPr2r2vrGirRbKAJw0zayJemuef6ng9XrATaS1M/8OTAH6AHsBPwb2LVeATQL6/jkdcRkrg0/fe6SzQ7BOUFfN84iY1fha0rnAJRFxbsEhHwGnS5oNnAd8q2xRmllVqsXmeVsLdhTaHGhtBfcXSAsWm5k1UYsLdhSbNN8FDmll32DS2ptmZjWv2ClHvweGS3oBuJPP+zS/R+rv3K884ZlZNavBcaCiF+y4VdIWwBDgAGAlYDIwDhgUEf8qX4hmVq0qvaldiqInt0fE03TQKLmZ1YZaHAjKdUeQpGWADYFVgRERMVVSd2BuRKUvUm9mHa0Wk0JRSVNSV9IjLY4EepC6KjYDpgK3Ak8BJ5YpRjOrUkHt1TSLHT0/AzgMOApYk6Z3Bd0B7N7OcZlZDWiI0rZKVmzz/CBgSET8Nat1FnqdlEjNzJpoqMGaZrFJszcpObZkCaB5IjUzq+vm+QvAwFb27QI83T7hmFktaShxq2TF1jRPA26V1AO4mTQQ9DVJ3weOIE1yNzNrohZrmsVObr9D0g+As0mrGgFcQXqU748i4h9lis/Mqlil1xpLkWdy+03ATZLWBZYnrXL0akQtrphnZu2hFpNmUX2akk6QtApARPwnIh6PiFciIiStLOmE8oZpZtUoUElbJSt2IOhEoF8r+1bBE9vNrAUNKm2rZMU2z0XrC5b0I90ZZGbWRF3N05Q0CBiUvQ3gUkkzmh3WHdgIuL884ZlZNavFAY+2apqfAB9mrwVMJw3+FJoLjAAuaf/QzMwqT1vPCLqZNCcTSX8FTomINzsqMDOrfrU4el5sn+YvgZ4t7ZC0MvBxRMxst6jMrCY0qI76NJu5gtQ8P6yFfScBvYD92ykmM6sRtdinWeyUo22Be1rZd2+238ysiXq+97wXaWCoJbOBZdonHDOrJZU+57IUxdY0XwO+28q+XWl92Tgzq2MNqKStkhWbNC8CjpJ0jqQvS1o2+/Ns0iMwLixfiGZWraLEbVEkrSpplKSXJL0o6ZdZ+bKSHpD0WvbnMlm5JP1J0nhJz0n6esG5BmXHv5bNT29TsascXS5pReB3wDEFu2YD/xsRlxdzHjOrL2Vsns8Dfh0RT0v6EvAvSQ8ABwMjI+JMSUNIjx0/jrTu7zrZtgVwKbCFpGVJt4FvSsrX/5J0Z0S0epdjnlWOTpN0EbAVsBxp4vs/I2J67q9rZnWhXIM6ETEJmJS9/ljSy0Bf0mLpA7LDrgZGk5LmQOCabFW2JyT1zqZLDgAeiIiPALLEuzNwQ2vXzvUI3yxB3pfnM2ZWvzpiypGkNYCNgbHAillCBZgMrJi97gu8W/CxCVlZa+Wtauve812BRyNiRva6TRFx76KOMbP6UmrzXNLhwOEFRUMjYmgLxy1Feoz4r7JctWBftnRlu+fttmqadwNbAk9mrwNaHdYK/HA1M2um1OZ5liAXSpKFJC1OSpjXRcTfs+L3Ja0cEZOy5veUrHwisGrBx/tlZRP5vDnfWD66reu2lTT7k/UZZK/NzHIpV5+mUpXySuDliDivYNedpNXZzsz+vKOg/ChJw0kDQdOzxPoP4IzGUXZgR9KAd6vaWrDj7ZZem5kVK8o3er418CPgeUnPZmW/JyXLmyQNBt4G9s323UuaUz6edKPOIQAR8ZGkU4Fx2XGnNA4KtaatPs3V8nyDiHgnz/FmVvvKOHr+KK13F27fwvFBmlPe0rmGAcOKvXZbzfO3yDf45T5NM2ui0u8jL0VbSXP3gtdLkx7f+zLwd1Lnah9gL2A94NhyBWhm1asWVzlqq09zwapGkq4C7o6InzY77DJJl5HuSx9elgjNzCpIsZPb9yTVKltyK3BL+4RjZrWknlc5+hT4Ziv7tiHdg25m1kQ9r6d5KXC8pOVI850a+zQHAkcAp5cnPDOrZpWeAEtR7CpHJ0maCvwW+Bmf3x00GfhNRFxQvhDNrFrV1UBQcxFxYbbK0Wqkm+AnA+9GRC3+MjGzdlCLfZp5VzlqkPQ26XnnU5wwzawttZggih0IQtKuksaSBn3eAb6SlQ+VdGCZ4jOzKlaulds7U1FJU9JBpAGgV0jLNRV+7jVgcPuHZmbVroEoaatkxdY0/wCcExGDgGub7XsR2KBdozKzmlDPU45WBx5oZd9s0m2WZmZNVHadsTTF1jTfJS0n35JNScstmZk1Uc81zSuBEyW9D9yelUnS9qS5m6eUIzgzq271POXoLNJS8VcD87Oyx0nLwf0lIv5UhtjMrMpV+qBOKYq9IyiAIyWdR1rgc3ngI+ChiPhPGeMzsypWeymziKQpqTswHdgvIm4HXi97VGZWEyq9f7IUi0yaETFb0hRgXgfEY2Y1pBab58WOnv8F+EX2yEwzs7pV7EBQb2BD4C1JI4H3adpdERFxXHsHZ2bVrfbqmcUnzb2AOdnrbVrYH4CTppk1UZd9mgAR0b/cgZhZ7anFPs02k6akHqQHrK8BTAJGRsT7HRCXmdWA2kuZbSRNSWsCD5ISZqMZkvaNiPvLHZiZVb9abJ63NXp+Nuk7bwMsCXwZeIY0km5mtkhR4n+VrK3m+VbAryPisez9y5KOyP5cOSImlT88M6tmtVjTbCtprgy80azsddID1VYi9XGambWq7gaCqM1+3E7Rr98qXDXsQvqsuDwRwRVXXMdFf76Sk086lt1335GGhuCDKf/lx4cezaRJ77P77jty8knH0tAQzJs3j1//+kQee3xcZ3+NujN//nz2G/wL+qywPJecczIH/fQ3zPrkUwA+mjqNjTb4H/505gkMu+4W7rl/1ILPvPH2uzxyz3B6Lf2lFs9TL2oxgSitxdHCDqkBmMbCt08u31J5RPQpR4CFFluib9X+Hay0Uh9WXqkPzzz7Akst1ZMnx97HXnv/mAkTJvHxxzMBOOrIH7P++uty5FFD6NlzSWbN+gSAjTZanxuuv4wNN/pWZ36FL+TT9x7p7BBKcvXwv/PiK68xc9YnCyW7X/3+NL69zZYM3GWHJuWjH32Ca268nWEXnVnUearB4suvWdIib0essU9J/2b/8tbNFbuoXFs1zer7m61gkydPYfLkKQDMnDmLV155jb6rrMTLL7+24JiePZek8ZdYY8IE6Lnk5+XWcSZP+YAxjz/J4YP25+rhtzXZN3PWLJ58+t+c9oejF/rcvQ8+zK7f+fwXXFvnqXV11acZER2WNCUdEhF/7ajrdbbVV+/H1766IWOffAaAU085jgN/uDfTZ8xgh+/ss+C4gQN35vTTfkefFZbjewMHdVa4deusC//CMT8bvKA5XmjkmH+yxSZfZamePZuUfzp7No8+8RR/OOZnRZ2n1lX6SHgpin6Eb5nVTa22Z88luenGyznmNycuaJYff8JZ9F9rM2644TaO/NkhC46944772HCjb7HX3oM5+aRjOyvkujT6sbEsu0xvvrzeOi3uH/Hgw+y6w4CFP/foWDb+ygYL+jIXdZ5aV8+Pu/jCJD3X2i5gxTY+dzjpscGoay+6dOnZ2qEVb7HFFuPmGy/nhhtu4/bbRyy0//ob/s5dd/6Nk085t0n5I4+OpX//1VhuuWX48MOpHRVuXXvmuZcY/egTPPLPccyZ+xmzZn3CcSefzVkn/pap06bz/MsvKBcAAAojSURBVEuvcuEZxy/0uREjmybTts5TD2qxptlhSZOUGHcCmv+rF+nRGS2KiKHAUKjugSCAy4eey8uvjOeCC4cuKFt77f6MH/8mAN/bfSdefTWt8bzWWmvw+utvAbDx1zakW7clnDA70NE/PYSjf5pq/U8+/RxX3XDrgkR3/6hH+dY3NqdbtyWafObjmbN46pnnOfOE3xZ1nnpQ6bXGUnRk0rwbWCoinm2+Q9LoDoyjU2z9jc340YF789zzL/HUuHQX6vHHn8khh+zPuuuuRUNDA++8M5GfHTkEgD2/vysHHrg3n302j9mfzuYHP/xpZ4ZvBUaMfJhDD9x3ofKRDz/ONzb/Okv26N4JUVWmhhocwGx1ylElqvaaZj2r1ilHlpQ65ehHq+9Z0r/Zv73996qccmRm9oXUYi3HSdPMyqYeb6M0MyuZR8/NzHLw6LmZWQ5unpuZ5eDmuZlZDm6em5nlUE3zwIvlpGlmZeM+TTOzHNw8NzPLwQNBZmY5uHluZpaDB4LMzHKoxT7NSnnchZnVoCjxv0WRNEzSFEkvFJQtK+kBSa9lfy6TlUvSnySNl/ScpK8XfGZQdvxrkop6EJeTppmVTQNR0laEq4Cdm5UNAUZGxDrAyOw9wC7AOtl2OHAppCQLnAhsAWwOnNiYaNvipGlmVScixgAfNSseCFydvb4a2KOg/JpIngB6S1qZ9PidByLio4iYCjzAwol4Ie7TNLOy6eCBoBUjYlL2ejKfP7CxL/BuwXETsrLWytvkmqaZlU2pzXNJh0t6qmA7PM91I2XrsmRs1zTNrGxKndxe+BTaHN6XtHJETMqa31Oy8onAqgXH9cvKJgIDmpWPXtRFXNM0s7JpiChpK9GdQOMI+CDgjoLyg7JR9C2B6Vkz/h/AjpKWyQaAdszK2uSappmVTbl6NCXdQKolLi9pAmkU/EzgJkmDgbeBxucs3wvsCowHPgEOAYiIjySdCozLjjslIpoPLi3ESdPMyqZct1FGxAGt7Nq+hWMDOLKV8wwDhuW5tpOmmZWN7z03M8vB956bmeXgmqaZWQ5eT9PMLAc3z83McnDz3MwsB9c0zcxycE3TzCwHDwSZmeXwBe4jr1hesMPMLAfXNM2sbNw8NzPLoRab506aZlY2rmmameXgmqaZWQ6uaZqZ5eCapplZDq5pmpnlENHQ2SG0OydNMysb33tuZpaDVzkyM8vBNU0zsxxc0zQzy8FTjszMcvCUIzOzHNw8NzPLwQNBZmY51GJN0yu3m5nl4JqmmZWNR8/NzHKoxea5k6aZlY0HgszMcnBN08wsB/dpmpnl4DuCzMxycE3TzCwH92mameXg5rmZWQ6uaZqZ5eCkaWaWQ+2lTFAt/iaoVpIOj4ihnR2HlcZ/f/XBqxxVlsM7OwD7Qvz3VwecNM3McnDSNDPLwUmzsrg/rLr5768OeCDIzCwH1zTNzHJw0qwQknaW9Kqk8ZKGdHY8VjxJwyRNkfRCZ8di5eekWQEkdQUuBnYBNgAOkLRB50ZlOVwF7NzZQVjHcNKsDJsD4yPijYiYCwwHBnZyTFakiBgDfNTZcVjHcNKsDH2BdwveT8jKzKzCOGmameXgpFkZJgKrFrzvl5WZWYVx0qwM44B1JPWXtASwP3BnJ8dkZi1w0qwAETEPOAr4B/AycFNEvNi5UVmxJN0A/BP4H0kTJA3u7JisfHxHkJlZDq5pmpnl4KRpZpaDk6aZWQ5OmmZmOThpmpnl4KRZ4SS9KSkkrV3CZzeXdFIZwiq8xmhJtxRxXBdJh0p6XNIMSbMlvSDpZEm9s2MGZN91w3LGbPZFOGlWMElbAWtkbw8o4RSbAye2W0AlktQFuBH4M2k+476kFZ2GAQdRATGaFcvPPa9sBwCzgBey16d2bjglOxLYE9gpIh4sKB8l6RJg684Jyyw/1zQrVLbG5r6k2ymHAetL+moLx20raZSkmZKmZ83ljSUdDFyUHRPZNjp7f5Wkp5qdZ43smN0Kyn4taVx23vcl3VVKNwFwNHB7s4QJQETMjoiRbfwcFhmDpG9KeiRr9s+Q9KykfQr2f0/SvyTNkjRV0lhJ3yrY30XSkGwB6DmS/iNpUJ5rWP1w0qxc3wZWJK2teQvwGc2a6JIGACOzfYOA/YBHSMvK3QOcmx26Vbb9LGcM/UhN6oHAYUBX4HFJvYo9gaRVgf7AfTmvXVQMkpYG7gbeAPYC9gb+BjT2k65F+vk9BOwO/DA7ftmCa1wE/C/pwWjfBW4DhjX+AlnUNazORIS3CtyAK4GpwBLZ+7uBt8hufc3K/gk8VVjW7BxHpb/ihcqvAp5qVrYGEMBurZyrK9AD+Bg4qKB8NHBLG99jy+y8OxXxnQdkx25YbAzAptlnvtTKZ/YGPmzjmmsDDcCgZuXXAOOKuYa3+tpc06xA2UpHewK3RVrJHVKNc3VSjRFJPYEtgKsjoiwLCEjaUtIDkj4E5gGfAEsB65ZwupJiLCKG14GZwPWSBjaOxBd4Hugl6WpJO2Y/t0Lbk5LmbZIWa9xINfivZd0ki7qG1REnzcq0C6npd6+k3tk/0tHAHD5voi8DCJhUjgAkrQbcn13jCNJgzWbAFKB7jlM1rgu6WjliiIipwHeAxYGbgA8k3SNpzWz/q6Sm/ZrAvcB/JV0vaYXsMsuTarDTSd0cjdtVpIHSlRd1DasvHj2vTI2J8eYW9u0j6VekpnsDsHIJ558NLNGsbJlm73cGlgQGRsQsgKwGtiw5RMS7kt4AdgKuyBlnUTFExBPAzpJ6ADsA5wHXk7oGiIh7gHuyftDvAheQ+jH3Jz3bZx4pITe0EMOUYq5h9cM1zQqTNR93B24gDQYVbseQBoe2y5LIWOAgSWrldHOzczavGU4A1mhWvmOzY3qQksi8grJ9Ke0X7QXAnpK+3XyHpO6Stmvlc7liiIhPI+Iu0myDhZ7mGRHTI+J60kBP4/6HSDXNXhHxVAvb3GbnaPMaVvtc06w8A0m1qwsjYmzhDkmPAX8g1UQfAIYADwIjJA0lzencijTIczfwSvbRX0p6CJiRNVdvB04BrpB0FbAx8ONmcTQmk79KuhL4MvAbYFoJ3+liYFtSd8PFWexzga+SBqvuyq7X3CJjkPTdLPbbgXdIMweOaDyfpCOyn8l9wHvAOsA+pIEeIuJVSZcBwyWdTRpY655da92IOHRR17A609kjUd6abqQE8p829l9CShrdsvffAsaQBkimAaOAr2X7BJxNShYNwOiC8xxMGuD4hDQy/w2ajZ4DP8qO+RR4gjTw9BbwfwXHjKaN0fOC47oAh2bnmUnqIniedDdQr+yYATQbPV9UDMD/kKYUvUvq850AXAYsm+3fijT96r3smm8CZzX+/Ap+Tr8CXszO8QHwMJ+P0Ld5DW/1tXnldjOzHNynaWaWg5OmmVkOTppmZjk4aZqZ5eCkaWaWg5OmmVkOTppmZjk4aZqZ5eCkaWaWw/8DGUWo9SWnzKoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report,  accuracy_score\n",
    "y_pred = model.predict_classes(x_test)\n",
    "\n",
    "print('\\nTesting accuracy:', (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "cfm_model = confusion_matrix(y_test, y_pred)\n",
    "print('\\n Confusion matrix:\\n', cfm_model)\n",
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "sns.heatmap(cfm_model, annot = True, fmt = 'd')\n",
    "plt.xlabel('Actual Classes', fontsize = 15)\n",
    "plt.ylabel('Predicted Classes', fontsize = 15)\n",
    "plt.title('Confusion Matrix ', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dUDSg7VeCzM",
    "outputId": "993bf04c-4b5c-4d53-a9e1-a4187be8b245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure alive especially when one of the soldiers is against all types of violence and another one continuously stares at video images of her cute 3 year old son the hills have eyes ii completely lacks  as to be expected  originality logic and plausible situations the mutated ? aren't nearly as menacing as their colleagues in part one mainly because they aren't organized this time and only just behave like ? and sex hungry prototype monsters since you don't care for the amateur g i joe heroes and definitely don't feel any sympathy for the eyes in the hills this film is a whole lot less compelling and involving than last year's original most ? this second film isn't nearly as violent and gory as the first sequels usually compensate the lack of suspense and the absence of surprise twists with extra bloodshed and more graphic killing sequences but the action in this sequel is really tame compared to the sick footage featuring in its predecessor there are a handful of scenes to satisfy the ? horror fanatics  mainly showing soldiers falling down ? or getting shot by their own guns  but there sadly aren't any outrageous pick axe battles or ? dog attacks what a shame what's the point of a sequel if it even fails to ? the level of ? and or gratuitous filth of the original luckily enough the film is never boring or unnecessarily sentimental and you'll have the most fun ? all the things that don't make the slightest bit of sense for example ? falling out of people's ? heads women without any muscle power cast as tough ass soldiers and  my personal favorite  ? the one soldier with a speaking ? to operate the radio ?\n",
      "ACTUAL sentiment: Negative\n",
      "PREDICTED sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Predicting the sentiment for a random pre-defined review from IMDB dataset\n",
    "review_id = np.random.choice(test_len)\n",
    "interprete_review(x_test[review_id])\n",
    "print('ACTUAL sentiment:', sentiments.get(y_test[review_id]))\n",
    "\n",
    "prediction = model.predict_classes(pad_sequences([x_test[review_id]], maxlen = maxlen))\n",
    "print('PREDICTED sentiment:', sentiments.get(prediction[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytXAowtDmWsa"
   },
   "source": [
    "### Output of each layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tskt_1npeCzP",
    "outputId": "fbe568f8-a16a-4938-8bf6-510ec01d3ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------------------------------------- embedding_3 layer ---------------------------------------- \n",
      "\n",
      "[[[-0.01087046 -0.02226283 -0.01529966 ...  0.00508994 -0.03526138\n",
      "   -0.01275799]\n",
      "  [-0.01087046 -0.02226283 -0.01529966 ...  0.00508994 -0.03526138\n",
      "   -0.01275799]\n",
      "  [-0.01087046 -0.02226283 -0.01529966 ...  0.00508994 -0.03526138\n",
      "   -0.01275799]\n",
      "  ...\n",
      "  [ 0.01491141  0.02168479 -0.02027915 ... -0.04847545  0.00731946\n",
      "    0.00660094]\n",
      "  [ 0.01491141  0.02168479 -0.02027915 ... -0.04847545  0.00731946\n",
      "    0.00660094]\n",
      "  [ 0.01491141  0.02168479 -0.02027915 ... -0.04847545  0.00731946\n",
      "    0.00660094]]]\n",
      "\n",
      " ---------------------------------------- dropout_2 layer ---------------------------------------- \n",
      "\n",
      "[[[-0.01087046 -0.02226283 -0.01529966 ...  0.00508994 -0.03526138\n",
      "   -0.01275799]\n",
      "  [-0.01087046 -0.02226283 -0.01529966 ...  0.00508994 -0.03526138\n",
      "   -0.01275799]\n",
      "  [-0.01087046 -0.02226283 -0.01529966 ...  0.00508994 -0.03526138\n",
      "   -0.01275799]\n",
      "  ...\n",
      "  [ 0.01491141  0.02168479 -0.02027915 ... -0.04847545  0.00731946\n",
      "    0.00660094]\n",
      "  [ 0.01491141  0.02168479 -0.02027915 ... -0.04847545  0.00731946\n",
      "    0.00660094]\n",
      "  [ 0.01491141  0.02168479 -0.02027915 ... -0.04847545  0.00731946\n",
      "    0.00660094]]]\n",
      "\n",
      " ---------------------------------------- conv1d_2 layer ---------------------------------------- \n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "WARNING:tensorflow:5 out of the last 1261 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07db09aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- conv1d_3 layer ---------------------------------------- \n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "WARNING:tensorflow:6 out of the last 1262 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07db10d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- max_pooling1d layer ---------------------------------------- \n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "WARNING:tensorflow:7 out of the last 1263 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07d8a79620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- conv1d_4 layer ---------------------------------------- \n",
      "\n",
      "[[[0.         0.0002435  0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.0098687  0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.00537674 0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.00778552 0.         0.        ]]]\n",
      "WARNING:tensorflow:8 out of the last 1264 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07db09a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- max_pooling1d_1 layer ---------------------------------------- \n",
      "\n",
      "[[[0.         0.0002435  0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03941858 0.08680209 0.         ... 0.         0.         0.        ]\n",
      "  [0.0060293  0.04185139 0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.00778552 0.         0.        ]]]\n",
      "WARNING:tensorflow:9 out of the last 1265 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07d89d58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- lstm layer ---------------------------------------- \n",
      "\n",
      "[[-0.19151153  0.10143767  0.07832322 -0.06405655 -0.10550614  0.22027205\n",
      "  -0.02570326 -0.19934374 -0.0150205   0.18913063  0.08023507  0.18648045\n",
      "  -0.07610591  0.08339389  0.08902894 -0.17344274  0.03678396 -0.09607615\n",
      "   0.17700492 -0.06554487 -0.17373022  0.06679252  0.00610841 -0.04886089\n",
      "  -0.07528172 -0.03350229  0.2800934   0.16554978 -0.208434    0.08087082\n",
      "   0.19748418 -0.08728465 -0.05580929  0.00697094 -0.03043655  0.14129983\n",
      "  -0.08098735  0.01253597 -0.03713344 -0.04428948 -0.1556909  -0.14436497\n",
      "   0.05656171  0.09305827 -0.01341171  0.27913392  0.10623356 -0.0152016\n",
      "  -0.18314339 -0.13094242 -0.08811034  0.22050987  0.04887928  0.00393663\n",
      "   0.14856611 -0.16946049  0.14851095  0.11706216 -0.00962404  0.17363445\n",
      "   0.1290676  -0.02051621  0.2079224  -0.02506685 -0.18603523 -0.15657933\n",
      "   0.11433037  0.12889443  0.00818098  0.09923322 -0.1636719  -0.22043264\n",
      "   0.0271089   0.15908007  0.11660759]]\n",
      "WARNING:tensorflow:10 out of the last 1266 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07e00b8ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- dense layer ---------------------------------------- \n",
      "\n",
      "[[0.7630335]]\n"
     ]
    }
   ],
   "source": [
    "sample_x_test = x_test[np.random.randint(10000)]\n",
    "for layer in model.layers:\n",
    "\n",
    "    model_layer = Model(inputs = model.input, outputs = model.get_layer(layer.name).output)\n",
    "    output = model_layer.predict(sample_x_test.reshape(1,-1))\n",
    "    print('\\n','--'*20, layer.name, 'layer', '--'*20, '\\n')\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yt0Ie6RQmrC3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SeqNLP_Project1_Questions-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
